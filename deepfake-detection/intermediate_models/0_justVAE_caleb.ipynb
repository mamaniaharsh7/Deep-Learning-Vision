{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNPkS0TnyV796YU1BIufnE2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"SaGNL8ZLwyc2"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import sklearn\n","import torch\n","import cv2\n","import os\n","import random\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n","from torch.utils.data import TensorDataset, DataLoader\n","from torchvision import transforms\n","from torchvision import models\n","from torchvision.datasets import ImageFolder\n","import torchvision.utils as vutils\n","from tqdm import tqdm\n","\n","import kagglehub\n","\n","# Download latest version\n","celebs_path = kagglehub.dataset_download(\"reubensuju/celeb-df-v2\")\n","\n","print(\"Path to dataset files:\", celebs_path)\n","\n","def extract_frames(video_path, filename, output_folder):\n","        # Create output folder if it doesn't exist\n","        if not os.path.exists(output_folder):\n","            os.makedirs(output_folder)\n","\n","        # Open the video file\n","        cap = cv2.VideoCapture(video_path)\n","\n","        if not cap.isOpened():\n","            print(f\"Error: Could not open video file {video_path}\")\n","            return\n","\n","        frame_count = 0\n","        while True:\n","            # Read a frame\n","            ret, frame = cap.read()\n","\n","            # If frame is not read successfully, break the loop\n","            if not ret:\n","                break\n","\n","            # Save the frame\n","            frame_filename = os.path.join(output_folder, f\"frame_{frame_count:05d}_{filename}.jpg\")\n","            cv2.imwrite(frame_filename, frame)\n","\n","            frame_count += 1\n","\n","        # Release the video capture object\n","        cap.release()\n","        print(f\"Extracted {frame_count} frames to {output_folder}\")\n","\n","with open(os.path.join(celebs_path, 'List_of_testing_videos.txt')) as f:\n","    lines = f.read().strip().split(\"\\n\")\n","    for line in lines:\n","        label_video = line.split(\" \")\n","        label = label_video[0]\n","        video = label_video[1]\n","        video_path = os.path.join(celebs_path, video)\n","        output_path = os.path.join(\"frames\", label)\n","        extract_frames(video_path, video[:-4].replace(\"/\", \"_\"), output_path)\n","\n","\n","#each image will be 64x64\n","image_size = 64\n","\n","celebs_image_dataset = ImageFolder(root=\"frames\",\n","                           transform=transforms.Compose([\n","                               transforms.Resize(image_size),\n","                               transforms.CenterCrop(image_size),\n","                               transforms.ToTensor(),\n","                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","                           ]))\n","\n","features_extract = []\n","labels_extract = []\n","for i in tqdm(range(len(celebs_image_dataset))):\n","    t = celebs_image_dataset[i]\n","    features_extract.append(t[0])\n","    labels_extract.append(t[1])\n","\n","X_unshuffled = torch.stack(features_extract, dim = 0)\n","y_unshuffled = torch.Tensor(labels_extract).type(torch.LongTensor)\n","\n","#convention: real = 0, fake = 1\n","real_mask = y_unshuffled == 1\n","fake_mask = y_unshuffled == 0\n","\n","y_unshuffled[real_mask] = 0\n","y_unshuffled[fake_mask] = 1\n","\n","\n","random.seed(0)\n","shuffle_mask = np.arange(0, len(X_unshuffled), 1)\n","random.shuffle(shuffle_mask)\n","\n","X_shuffled = X_unshuffled[shuffle_mask]\n","y_shuffled = y_unshuffled[shuffle_mask]\n","\n","n_real = 25000\n","n_fake = 25000\n","\n","real_indices = torch.argwhere(y_shuffled == 0).T.squeeze()\n","fake_indices = torch.argwhere(y_shuffled == 1).T.squeeze()\n","\n","sample_indices = torch.cat([real_indices[:n_real], fake_indices[:n_fake]], dim=0)\n","\n","torch.save(X_shuffled[sample_indices], \"X_celebs_df_2.pt\")\n","torch.save(y_shuffled[sample_indices], \"y_celebs_df_2.pt\")\n","print(\"Feature size:\", X_shuffled.shape)\n","print(\"Label size:\", y_shuffled.shape)\n","\n","X_sample = torch.load(\"X_celebs_df_2.pt\")\n","y_sample = torch.load(\"y_celebs_df_2.pt\")\n","\n","random.seed(0)\n","shuffle_mask = np.arange(0, len(X_sample), 1)\n","random.shuffle(shuffle_mask)\n","\n","X_sample = X_sample[shuffle_mask]\n","y_sample = y_sample[shuffle_mask]\n","\n","print(X_sample.shape)\n","print(y_sample.shape)\n","\n","\n","class ResNetClassifier:\n","\n","    def __init__(self, resnet_model: nn.Module = None, k:int=2, lr:float=1e-3, epochs: int=10, batch_size: int=64,\n","                 optimizer_func: torch.optim.Optimizer = torch.optim.Adam):\n","\n","        assert resnet_model is not None\n","        self.model = nn.Sequential(resnet_model, nn.Linear(1000, k), nn.Softmax(dim=1))\n","        self.lr = lr\n","        self.epochs = epochs\n","        self.batch_size = batch_size\n","        self.optimizer_func = optimizer_func\n","\n","\n","    def eval(self, train_X: torch.Tensor, train_y: torch.Tensor, test_X: torch.Tensor, test_y: torch.Tensor):\n","        self.model.eval()\n","        train_pred_y = self.predict(train_X)\n","        test_pred_y = self.predict(test_X)\n","\n","        acc_train = accuracy_score(train_y, train_pred_y)\n","        acc_test = accuracy_score(test_y, test_pred_y)\n","\n","        criterion = nn.CrossEntropyLoss()\n","        loss_train = criterion(self.model(train_X), train_y).detach()\n","        loss_test =  criterion(self.model(test_X), test_y).detach()\n","\n","        return acc_train, acc_test, loss_train, loss_test\n","\n","\n","    def fit(self, X: torch.Tensor, y: torch.Tensor):\n","\n","        criterion = nn.CrossEntropyLoss()\n","        optimizer = self.optimizer_func(self.model.parameters(), self.lr)\n","\n","        train_X, test_X, train_y, test_y = train_test_split(X, y, test_size= 0.2)\n","        train_tensor = TensorDataset(train_X, train_y)\n","        train_loader = DataLoader(train_tensor, batch_size=self.batch_size, shuffle=True)\n","\n","        self.train_losses = []\n","        self.test_losses = []\n","        self.train_acces = []\n","        self.test_acces = []\n","        for i in range(self.epochs):\n","            self.model.train()\n","\n","            for batch in train_loader:\n","                #extract features (X) and labels (y)\n","                X_tensor, y_tensor = batch\n","\n","                #extract the hypothesis for X (the probabilities according to our model)\n","                h_X = self.model(X_tensor)\n","\n","                #compute cross entropy loss\n","                loss = criterion(h_X, y_tensor)\n","\n","                #update the model's parameters using gradient ascent and backpropagation\n","                loss.backward()\n","                optimizer.step()\n","                optimizer.zero_grad()\n","\n","                acc_train, acc_test, loss_train, loss_test = self.eval(train_X, train_y, test_X, test_y)\n","\n","                self.train_losses.append(loss_train)\n","                self.test_losses.append(loss_test)\n","                self.train_acces.append(acc_train)\n","                self.test_acces.append(acc_test)\n","\n","            print(\"Epoch {} Complete: Train Loss = {}, Test Loss = {}, Train Accuracy = {}%, Test Accuracy = {}%\".format(i, loss_train, loss_test, acc_train*100, acc_test*100))\n","\n","    def plot_results(self):\n","        n_epochs = len(self.train_losses)\n","        epochs = np.arange(n_epochs)\n","        plt.plot(epochs, self.train_losses, label=\"Train Loss\", c='r')\n","        plt.plot(epochs, self.test_losses, label=\"Test Loss\", c='b')\n","        plt.xlabel(\"Mini Epochs\")\n","        plt.ylabel(\"Binary Cross Entropy Loss\")\n","        plt.legend()\n","        plt.show()\n","\n","        plt.plot(epochs, self.train_acces, label=\"Train Accuracy\", c='r')\n","        plt.plot(epochs, self.test_acces, label=\"Test Accuracy\", c='b')\n","        plt.xlabel(\"Mini Epochs\")\n","        plt.ylabel(\"Accuracy\")\n","        plt.legend()\n","        plt.show()\n","\n","\n","    def predict(self, X):\n","        self.model.eval()\n","        #extract the hypothesis for X (the probabilities according to our model)\n","        h_X = self.model(X)\n","        #give a prediction based on which class probability is higher\n","        _, preds = torch.max(h_X, dim=1)\n","        return preds.detach()\n","\n","resnet18 = models.resnet18(weights=None)\n","resnet18_deepfake_classifier = ResNetClassifier(resnet_model=resnet18, lr=1e-4, epochs = 10, batch_size=32)\n","\n","resnet18_deepfake_classifier.fit(X_sample[:1000], y_sample[:1000])\n","\n","resnet18_deepfake_classifier.plot_results()\n","\n","\n","class ConvEncoder(nn.Module):\n","    def __init__(self, in_channels=3, hidden_channels = [32, 64, 128], out_channels=256, input_height=64, input_width=64, latent_dim=128):\n","        super().__init__()\n","\n","        output_height = input_height // 2 ** (len(hidden_channels) + 1)\n","        output_width = input_width // 2 ** (len(hidden_channels) + 1)\n","\n","        layers = []\n","        layers.append(nn.Conv2d(in_channels, hidden_channels[0], kernel_size=4, stride=2, padding=1))\n","        layers.append(nn.ReLU(True))\n","        for k in range(0, len(hidden_channels)-1):\n","            layers.append(nn.Conv2d(hidden_channels[k], hidden_channels[k+1], kernel_size=4, stride=2, padding=1))\n","            layers.append(nn.BatchNorm2d(hidden_channels[k+1]))\n","            layers.append(nn.ReLU(True))\n","        layers.append(nn.Conv2d(hidden_channels[-1], out_channels, kernel_size=4, stride=2, padding=1))\n","        self.net = nn.Sequential(*layers)\n","\n","        self.flatten = nn.Flatten()\n","        self.fc_mu = nn.Linear(out_channels * output_height * output_width, latent_dim)\n","        self.fc_logvar = nn.Linear(out_channels * output_height * output_width, latent_dim)\n","\n","    def forward(self, x):\n","        x = self.net(x)\n","        x = self.flatten(x)\n","        mu = self.fc_mu(x)\n","        logvar = self.fc_logvar(x)\n","        return mu, logvar\n","\n","class ConvDecoder(nn.Module):\n","    def __init__(self, in_channels=256, hidden_channels = [128, 64, 32], out_channels=3, output_height=64, output_width=64, latent_dim=128):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.input_height = output_height // 2 ** (len(hidden_channels) + 1)\n","        self.input_width = output_width // 2 ** (len(hidden_channels) + 1)\n","\n","        self.fc = nn.Linear(latent_dim, self.in_channels * self.input_height * self.input_width)\n","        layers = []\n","        layers.append(nn.ConvTranspose2d(in_channels, hidden_channels[0], kernel_size=4, stride=2, padding=1))\n","        layers.append(nn.ReLU(True))\n","        for k in range(0, len(hidden_channels)-1):\n","            layers.append(nn.ConvTranspose2d(hidden_channels[k], hidden_channels[k+1], kernel_size=4, stride=2, padding=1))\n","            layers.append(nn.BatchNorm2d(hidden_channels[k+1]))\n","            layers.append(nn.ReLU(True))\n","        layers.append(nn.ConvTranspose2d(hidden_channels[-1], out_channels, kernel_size=4, stride=2, padding=1))\n","        self.net = nn.Sequential(*layers)\n","\n","    def forward(self, z):\n","        x = self.fc(z)\n","        x = x.view(-1, self.in_channels, self.input_height, self.input_width)\n","        x = self.net(x)\n","        return x\n","\n","class VAELoss(nn.Module):\n","\n","    def __init__(self):\n","\n","        super().__init__()\n","\n","    def forward(self, x, x_hat, mu, logvar):\n","\n","        recon_loss = F.mse_loss(x_hat, x, reduction='sum')\n","\n","        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n","\n","        return (recon_loss + kl_loss) / x.size(0)\n","\n","class ConvVAE(nn.Module):\n","\n","    def __init__(self, in_channels=3, hidden_channels = [32, 64, 128], out_channels = 256, height=64, width=64, latent_dim=128):\n","\n","        super().__init__()\n","\n","        self.encoder = ConvEncoder(in_channels, hidden_channels, out_channels, height, width, latent_dim)\n","\n","        self.decoder = ConvDecoder(out_channels, hidden_channels[::-1], in_channels, height, width, latent_dim)\n","\n","    def reparameterize(self, mu, logvar):\n","\n","        std = torch.exp(0.5 * logvar)\n","\n","        eps = torch.randn_like(std)\n","\n","        return mu + eps * std\n","\n","    def forward(self, x):\n","\n","        mu, logvar = self.encoder(x)\n","\n","        z = self.reparameterize(mu, logvar)\n","\n","        x_hat = self.decoder(z)\n","\n","        return x_hat, mu, logvar\n","\n","\n","class VAEWrapper:\n","\n","    def __init__(self, in_channels=3, hidden_channels = [128, 64, 32], out_channels = 256, height=64, width=64, latent_dim=128, lr:float=1e-3,\n","\n","                 epochs: int=10, batch_size: int=64, optimizer_func: torch.optim.Optimizer = torch.optim.Adam):\n","\n","        self.latent_dim = latent_dim\n","\n","        self.model = ConvVAE(in_channels, hidden_channels, out_channels, height, width, self.latent_dim)\n","\n","        self.lr = lr\n","\n","        self.epochs = epochs\n","\n","        self.batch_size = batch_size\n","\n","        self.optimizer_func = optimizer_func\n","\n","\n","    def fit(self, X):\n","\n","        criterion = VAELoss()\n","\n","        optimizer = self.optimizer_func(self.model.parameters(), self.lr)\n","\n","        train_tensor = TensorDataset(X)\n","\n","        train_loader = DataLoader(train_tensor, batch_size=self.batch_size, shuffle=True)\n","\n","        for i in range(self.epochs):\n","\n","            total_loss = 0\n","\n","            self.model.train()\n","\n","            for batch in train_loader:\n","\n","                imgs = batch[0]\n","\n","                x_hat, mu, logvar = self.model(imgs)\n","\n","                loss = criterion(imgs, x_hat, mu, logvar)\n","\n","                loss.backward()\n","\n","                optimizer.step()\n","\n","                optimizer.zero_grad()\n","\n","                total_loss += loss.item()\n","\n","            print(\"Epoch {} Complete: VAE Custom Loss = {}\".format(i, total_loss / len(train_loader)))\n","\n","    def reconstruction_loss_weights(self, X):\n","\n","        self.model.eval()\n","\n","        X_hat, _, _ = self.model(X)\n","\n","        recon_error = (X - X_hat).pow(2)\n","\n","        per_image_mse = recon_error.mean(dim=[1, 2, 3])\n","\n","        weights = F.softmax(2.0 * recon_error, dim=0)\n","\n","        return weights\n","\n","\n","    def generate_images(self, z):\n","\n","        assert z.shape[-1] == self.latent_dim\n","\n","        self.model.eval()\n","\n","        with torch.no_grad():\n","\n","            samples = self.model.decoder(z)\n","\n","\n","        return samples\n","\n","vae = VAEWrapper()\n","\n","vae.fit(real_imgs[:20000])\n","\n","samples = vae.generate_images(torch.rand((64, 128)))\n","\n","def reconstruction_weighted_BCEloss(x_hat, x, y_prob, y):\n","\n","    '''\n","    x_hat: vae reconstruction\n","    x: input image\n","    y_prob: CNN classifier output class probabilities (0-1)\n","    y: class label for input image\n","    '''\n","\n","    criterion = nn.BCELoss(reduction='none')\n","\n","    bce_per_image = criterion(y_prob, y)\n","\n","    recon_error = ((x - x_hat)**2).mean(dim=[1,2,3])\n","\n","    weights = F.softmax(2.0 * recon_error, dim=0)\n","\n","    weighted_loss = (bce_per_image * weights).sum()\n","\n","    return weighted_loss\n"]}]}