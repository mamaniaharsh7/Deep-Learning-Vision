{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMR2SR6wlF50wKLGV4LHPO5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Vanilla CNN"],"metadata":{"id":"5MpOrgCkvbZN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IwzqbnLMtc-K"},"outputs":[],"source":["# Uncomment if needed:\n","# !pip install -q torch torchvision scikit-learn matplotlib seaborn\n","\n","# Standard libraries\n","import os\n","import random\n","import numpy as np\n","import zipfile\n","from pathlib import Path\n","\n","# PyTorch\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset, DataLoader, random_split\n","\n","# Visualization\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Metrics\n","from sklearn.metrics import (\n","    accuracy_score,\n","    precision_score,\n","    recall_score,\n","    f1_score,\n","    roc_auc_score,\n","    roc_curve,\n","    confusion_matrix\n",")\n","\n","# Misc\n","from tqdm import tqdm\n","import time\n","\n","print(\"All libraries imported successfully!\")\n","\n","print(f\"PyTorch version: {torch.__version__}\")\n","print(f\"CUDA available: {torch.cuda.is_available()}\")\n","\n","\n","# Set random seeds for reproducibility\n","RANDOM_SEED = 42\n","\n","random.seed(RANDOM_SEED)\n","np.random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)\n","torch.cuda.manual_seed(RANDOM_SEED)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","print(\"‚úÖ Google Drive mounted successfully!\")\n","\n","# Define path to your zip file (no quotes around folder names!)\n","ZIP_PATH = '/content/drive/MyDrive/NEU - MS CS/3_SEM/CS - 7150 (DeepLearning)/midterm-proj-1/data/faceforensics_dataset.zip'\n","\n","# Check if file exists\n","if os.path.exists(ZIP_PATH):\n","    file_size = os.path.getsize(ZIP_PATH) / (1024**3)  # GB\n","    print(f\"‚úÖ Found dataset: {os.path.basename(ZIP_PATH)}\")\n","    print(f\"   Size: {file_size:.2f} GB\")\n","else:\n","    print(f\"‚ùå File not found: {ZIP_PATH}\")\n","    print(f\"   Please check the path!\")\n","\n","# Check for GPU availability\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","print(f\"üñ•Ô∏è Device Configuration:\")\n","print(f\"   Device: {device}\")\n","\n","if device.type == 'cuda':\n","    print(f\"   GPU Name: {torch.cuda.get_device_name(0)}\")\n","    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.2f} GB\")\n","    print(f\"   ‚úÖ Using GPU for training!\")\n","else:\n","    print(f\"   ‚ö†Ô∏è GPU not available, using CPU\")\n","    print(f\"   Note: Training will be much slower on CPU\")\n","\n","# Training configuration\n","CONFIG = {\n","    # Data\n","    'batch_size': 64,              # Number of samples per batch\n","    'num_workers': 2,              # Parallel data loading (2 for Colab)\n","\n","    # Training\n","    'num_epochs': 10,              # Total training epochs\n","    'learning_rate': 0.001,        # Learning rate for optimizer\n","\n","    # Checkpoints\n","    'checkpoint_interval': 10000,  # Save checkpoint every 10k samples\n","    'save_dir': '/content/drive/MyDrive/NEU - MS CS/3_SEM/CS - 7150 (Deep Learning)/midterm-proj-1/models',\n","\n","    # Data split\n","    'train_size': 90000,           # 90k for training\n","    'test_size': 10000,            # 10k for testing\n","\n","    # Model\n","    'input_channels': 3,           # RGB images\n","    'image_size': 64,              # 64x64 images\n","    'num_classes': 2,              # Binary: Real vs Fake\n","}\n","\n","# Create save directory if it doesn't exist\n","os.makedirs(CONFIG['save_dir'], exist_ok=True)\n","\n","print(\"üìã Configuration:\")\n","for key, value in CONFIG.items():\n","    print(f\"   {key}: {value}\")\n","\n","print(f\"\\n‚úÖ Configuration set!\")\n","\n","# Define extraction directory\n","EXTRACT_DIR = '/content/extracted_data'\n","\n","# Create directory if it doesn't exist\n","os.makedirs(EXTRACT_DIR, exist_ok=True)\n","\n","print(f\"üìÇ Extracting to: {EXTRACT_DIR}\")\n","print(f\"‚è≥ This may take a moment...\")\n","\n","start_time = time.time()\n","\n","# Extract zip file\n","with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n","    zip_ref.extractall(EXTRACT_DIR)\n","\n","elapsed = time.time() - start_time\n","\n","print(f\"‚úÖ Extraction complete in {elapsed:.2f} seconds\")\n","\n","# List extracted files\n","print(f\"\\nüìÑ Extracted files:\")\n","extracted_files = os.listdir(EXTRACT_DIR)\n","for file in extracted_files:\n","    file_path = os.path.join(EXTRACT_DIR, file)\n","    if os.path.isfile(file_path):\n","        size_mb = os.path.getsize(file_path) / (1024**2)\n","        print(f\"   ‚Ä¢ {file} ({size_mb:.2f} MB)\")\n","\n","\n","print(\"\\nüì• LOADING TENSORS\")\n","print(\"=\"*60)\n","\n","# Define paths to extracted tensor files\n","X_path = os.path.join(EXTRACT_DIR, 'FaceForensics_X.pt')\n","y_path = os.path.join(EXTRACT_DIR, 'FaceForensics_y.pt')\n","\n","# Check if files exist\n","if not os.path.exists(X_path):\n","    print(f\"‚ùå X tensor not found at: {X_path}\")\n","    raise FileNotFoundError(\"X tensor file missing!\")\n","\n","if not os.path.exists(y_path):\n","    print(f\"‚ùå y tensor not found at: {y_path}\")\n","    raise FileNotFoundError(\"y tensor file missing!\")\n","\n","print(f\"üìÇ Loading X tensor from: {os.path.basename(X_path)}\")\n","X = torch.load(X_path)\n","\n","print(f\"üìÇ Loading y tensor from: {os.path.basename(y_path)}\")\n","y = torch.load(y_path)\n","\n","print(f\"\\n‚úÖ Tensors loaded successfully!\")\n","\n","# Display tensor information\n","print(f\"\\nüìä Tensor Information:\")\n","print(f\"   X shape: {X.shape} (N, C, H, W)\")\n","print(f\"   y shape: {y.shape} (N,)\")\n","print(f\"   X dtype: {X.dtype}\")\n","print(f\"   y dtype: {y.dtype}\")\n","print(f\"   X range: [{X.min():.4f}, {X.max():.4f}]\")\n","print(f\"   y unique values: {torch.unique(y).tolist()}\")\n","\n","# Memory usage\n","X_memory = X.element_size() * X.nelement() / (1024**3)\n","y_memory = y.element_size() * y.nelement() / (1024**2)\n","\n","print(f\"\\nüíæ Memory Usage:\")\n","print(f\"   X tensor: {X_memory:.2f} GB\")\n","print(f\"   y tensor: {y_memory:.2f} MB\")\n","\n","# Count samples per class\n","unique_labels, counts = torch.unique(y, return_counts=True)\n","\n","print(f\"üìä Label Distribution:\")\n","for label, count in zip(unique_labels, counts):\n","    label_name = \"Real\" if label == 0 else \"Fake\"\n","    percentage = (count / len(y)) * 100\n","    print(f\"   {label} ({label_name}): {count:,} samples ({percentage:.1f}%)\")\n","\n","# Check balance\n","balance_ratio = counts[0].item() / counts[1].item()\n","print(f\"\\n‚öñÔ∏è Balance Ratio: {balance_ratio:.3f}:1\")\n","\n","if 0.95 <= balance_ratio <= 1.05:\n","    print(f\"   ‚úÖ Dataset is well balanced!\")\n","else:\n","    print(f\"   ‚ö†Ô∏è Dataset has imbalance\")\n","\n","# Check for any issues\n","print(f\"\\nüîç Data Quality Checks:\")\n","print(f\"   NaN in X: {torch.isnan(X).any().item()}\")\n","print(f\"   Inf in X: {torch.isinf(X).any().item()}\")\n","print(f\"   All y values valid (0 or 1): {torch.all((y == 0) | (y == 1)).item()}\")\n","\n","if torch.isnan(X).any() or torch.isinf(X).any():\n","    print(f\"   ‚ùå Warning: Data contains NaN or Inf values!\")\n","else:\n","    print(f\"   ‚úÖ No NaN or Inf values detected\")\n","\n","\n","print(\"\\nüîÄ SHUFFLING DATA\")\n","print(\"=\"*60)\n","\n","# Get total number of samples\n","num_samples = X.shape[0]\n","\n","# Create indices for all samples\n","indices = torch.randperm(num_samples)\n","\n","# Shuffle X and y using the same indices\n","X_shuffled = X[indices]\n","y_shuffled = y[indices]\n","\n","print(f\"‚úÖ Data shuffled with random seed {RANDOM_SEED}\")\n","\n","# Verify shuffle worked\n","print(f\"\\nüîç Verification:\")\n","print(f\"   Original first 10 labels: {y[:10].tolist()}\")\n","print(f\"   Shuffled first 10 labels: {y_shuffled[:10].tolist()}\")\n","print(f\"   (Should be different)\")\n","\n","# Verify data integrity after shuffle\n","assert X_shuffled.shape == X.shape, \"X shape changed after shuffle!\"\n","assert y_shuffled.shape == y.shape, \"y shape changed after shuffle!\"\n","assert len(torch.unique(y_shuffled)) == 2, \"Labels corrupted after shuffle!\"\n","\n","print(f\"\\n‚úÖ Shuffle verified - data integrity maintained\")\n","\n","# Replace original tensors with shuffled versions\n","X = X_shuffled\n","y = y_shuffled\n","\n","# Clean up\n","del X_shuffled, y_shuffled\n","\n","print(\"\\n‚úÇÔ∏è TRAIN/TEST SPLIT\")\n","print(\"=\"*60)\n","\n","# Use 90/10 ratio instead of fixed numbers\n","train_ratio = 0.9\n","test_ratio = 0.1\n","\n","# Calculate split sizes based on actual dataset size\n","num_samples = len(X)\n","train_size = int(num_samples * train_ratio)\n","test_size = num_samples - train_size  # Remaining samples go to test\n","\n","print(f\"üìä Split Configuration:\")\n","print(f\"   Total samples: {num_samples:,}\")\n","print(f\"   Train ratio: {train_ratio*100:.0f}%\")\n","print(f\"   Test ratio: {test_ratio*100:.0f}%\")\n","print(f\"   Calculated train size: {train_size:,}\")\n","print(f\"   Calculated test size: {test_size:,}\")\n","\n","# Verify\n","assert train_size + test_size == num_samples, \"Split calculation error!\"\n","\n","# Split data\n","X_train = X[:train_size]\n","y_train = y[:train_size]\n","\n","X_test = X[train_size:]  # All remaining samples\n","y_test = y[train_size:]\n","\n","print(f\"\\n‚úÖ Split Complete:\")\n","print(f\"   Train samples: {len(X_train):,} ({len(X_train)/num_samples*100:.1f}%)\")\n","print(f\"   Test samples: {len(X_test):,} ({len(X_test)/num_samples*100:.1f}%)\")\n","\n","# Check label distribution in splits\n","train_real = (y_train == 0).sum().item()\n","train_fake = (y_train == 1).sum().item()\n","test_real = (y_test == 0).sum().item()\n","test_fake = (y_test == 1).sum().item()\n","\n","print(f\"\\nüìä Train Set Distribution:\")\n","print(f\"   Real (0): {train_real:,} ({train_real/len(y_train)*100:.1f}%)\")\n","print(f\"   Fake (1): {train_fake:,} ({train_fake/len(y_train)*100:.1f}%)\")\n","\n","print(f\"\\nüìä Test Set Distribution:\")\n","print(f\"   Real (0): {test_real:,} ({test_real/len(y_test)*100:.1f}%)\")\n","print(f\"   Fake (1): {test_fake:,} ({test_fake/len(y_test)*100:.1f}%)\")\n","\n","# Verify balance\n","train_balance = train_real / train_fake if train_fake > 0 else 0\n","test_balance = test_real / test_fake if test_fake > 0 else 0\n","\n","print(f\"\\n‚öñÔ∏è Balance Check:\")\n","print(f\"   Train balance: {train_balance:.3f}:1\")\n","print(f\"   Test balance: {test_balance:.3f}:1\")\n","\n","if 0.9 <= train_balance <= 1.1 and 0.9 <= test_balance <= 1.1:\n","    print(f\"   ‚úÖ Both splits are well balanced!\")\n","else:\n","    print(f\"   ‚ö†Ô∏è Some imbalance detected (still acceptable)\")\n","\n","# Clean up original tensors to free memory\n","del X, y\n","import gc\n","gc.collect()\n","\n","print(f\"\\n‚úÖ Split complete and original tensors cleared from memory\")\n","\n","# Create TensorDatasets\n","train_dataset = TensorDataset(X_train, y_train)\n","test_dataset = TensorDataset(X_test, y_test)\n","\n","print(f\"üì¶ Datasets created:\")\n","print(f\"   Train dataset: {len(train_dataset):,} samples\")\n","print(f\"   Test dataset: {len(test_dataset):,} samples\")\n","\n","# Create DataLoaders\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=CONFIG['batch_size'],\n","    shuffle=True,              # Shuffle batches for training\n","    num_workers=CONFIG['num_workers'],\n","    pin_memory=True           # Faster data transfer to GPU\n",")\n","\n","test_loader = DataLoader(\n","    test_dataset,\n","    batch_size=CONFIG['batch_size'],\n","    shuffle=False,            # Don't shuffle test set\n","    num_workers=CONFIG['num_workers'],\n","    pin_memory=True\n",")\n","\n","print(f\"\\nüîÑ DataLoaders created:\")\n","print(f\"   Batch size: {CONFIG['batch_size']}\")\n","print(f\"   Train batches: {len(train_loader):,}\")\n","print(f\"   Test batches: {len(test_loader):,}\")\n","\n","# Calculate samples per epoch\n","samples_per_epoch = len(train_loader) * CONFIG['batch_size']\n","print(f\"\\nüìä Training Info:\")\n","print(f\"   Samples per epoch: {samples_per_epoch:,}\")\n","print(f\"   Batches per epoch: {len(train_loader):,}\")\n","print(f\"   Epochs planned: {CONFIG['num_epochs']}\")\n","print(f\"   Total training steps: {len(train_loader) * CONFIG['num_epochs']:,}\")\n","\n","# Checkpoint calculation\n","batches_per_checkpoint = CONFIG['checkpoint_interval'] // CONFIG['batch_size']\n","print(f\"\\nüíæ Checkpoint Info:\")\n","print(f\"   Checkpoint every: {CONFIG['checkpoint_interval']:,} samples\")\n","print(f\"   That's every: {batches_per_checkpoint} batches\")\n","print(f\"   Expected checkpoints per epoch: {len(train_loader) // batches_per_checkpoint}\")\n","\n","print(f\"\\n‚úÖ DataLoaders ready for training!\")\n","\n","class SimpleCNN(nn.Module):\n","    \"\"\"\n","    Simple CNN for binary classification (Real vs Fake)\n","    Architecture: Conv layers ‚Üí Flatten ‚Üí FC layers ‚Üí Output\n","    \"\"\"\n","\n","    def __init__(self, input_channels=3, num_classes=2):\n","        \"\"\"\n","        Initialize the CNN model\n","\n","        Args:\n","            input_channels (int): Number of input channels (3 for RGB)\n","            num_classes (int): Number of output classes (2 for binary)\n","        \"\"\"\n","        super(SimpleCNN, self).__init__()\n","\n","        # Convolutional Layer 1\n","        # Input: (batch, 3, 64, 64)\n","        # Output: (batch, 16, 32, 32)\n","        self.conv1 = nn.Conv2d(\n","            in_channels=input_channels,   # 3 (RGB)\n","            out_channels=16,               # 16 feature maps\n","            kernel_size=3,                 # 3x3 filter\n","            stride=1,                      # Move 1 pixel at a time\n","            padding=1                      # Pad to maintain size\n","        )\n","        self.relu1 = nn.ReLU()            # Activation function\n","        self.pool1 = nn.MaxPool2d(\n","            kernel_size=2,                 # 2x2 pooling window\n","            stride=2                       # Reduces size by half\n","        )\n","\n","        # Convolutional Layer 2\n","        # Input: (batch, 16, 32, 32)\n","        # Output: (batch, 32, 16, 16)\n","        self.conv2 = nn.Conv2d(\n","            in_channels=16,\n","            out_channels=32,\n","            kernel_size=3,\n","            stride=1,\n","            padding=1\n","        )\n","        self.relu2 = nn.ReLU()\n","        self.pool2 = nn.MaxPool2d(\n","            kernel_size=2,\n","            stride=2\n","        )\n","\n","        # Fully Connected Layers (MLP)\n","        # After conv layers: (batch, 32, 16, 16)\n","        # Flatten: (batch, 32*16*16) = (batch, 8192)\n","        self.flatten = nn.Flatten()\n","\n","        self.fc1 = nn.Linear(\n","            in_features=32 * 16 * 16,     # 8192 input features\n","            out_features=128               # 128 hidden units\n","        )\n","        self.relu3 = nn.ReLU()\n","\n","        self.fc2 = nn.Linear(\n","            in_features=128,\n","            out_features=num_classes       # 2 output classes\n","        )\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass through the network\n","\n","        Args:\n","            x (torch.Tensor): Input images (batch, 3, 64, 64)\n","\n","        Returns:\n","            torch.Tensor: Class logits (batch, 2)\n","        \"\"\"\n","        # Conv block 1\n","        x = self.conv1(x)      # (batch, 3, 64, 64) ‚Üí (batch, 16, 64, 64)\n","        x = self.relu1(x)      # Apply ReLU activation\n","        x = self.pool1(x)      # (batch, 16, 64, 64) ‚Üí (batch, 16, 32, 32)\n","\n","        # Conv block 2\n","        x = self.conv2(x)      # (batch, 16, 32, 32) ‚Üí (batch, 32, 32, 32)\n","        x = self.relu2(x)\n","        x = self.pool2(x)      # (batch, 32, 32, 32) ‚Üí (batch, 32, 16, 16)\n","\n","        # Flatten\n","        x = self.flatten(x)    # (batch, 32, 16, 16) ‚Üí (batch, 8192)\n","\n","        # Fully connected layers\n","        x = self.fc1(x)        # (batch, 8192) ‚Üí (batch, 128)\n","        x = self.relu3(x)\n","        x = self.fc2(x)        # (batch, 128) ‚Üí (batch, 2)\n","\n","        return x\n","\n","# Create model instance\n","model = SimpleCNN(\n","    input_channels=CONFIG['input_channels'],\n","    num_classes=CONFIG['num_classes']\n",")\n","\n","# Move model to GPU/CPU\n","model = model.to(device)\n","\n","print(f\"‚úÖ Model created and moved to {device}\")\n","\n","# Count parameters\n","total_params = sum(p.numel() for p in model.parameters())\n","trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f\"\\nüìä Model Statistics:\")\n","print(f\"   Total parameters: {total_params:,}\")\n","print(f\"   Trainable parameters: {trainable_params:,}\")\n","print(f\"   Model size: {total_params * 4 / (1024**2):.2f} MB (float32)\")\n","\n","print(model)\n","\n","print(\"\\n\" + \"=\"*60)\n","\n","# Test forward pass with dummy input\n","print(\"\\nüß™ Testing forward pass...\")\n","dummy_input = torch.randn(1, 3, 64, 64).to(device)  # Batch of 1 image\n","dummy_output = model(dummy_input)\n","\n","print(f\"‚úÖ Forward pass successful!\")\n","print(f\"   Input shape: {dummy_input.shape}\")\n","print(f\"   Output shape: {dummy_output.shape}\")\n","print(f\"   Output (logits): {dummy_output}\")\n","print(f\"\\nüí° Interpretation:\")\n","print(f\"   Output has 2 values: [score_for_class_0, score_for_class_1]\")\n","print(f\"   Higher score = model's prediction for that class\")\n","\n","# Loss function for classification\n","criterion = nn.CrossEntropyLoss()\n","\n","print(f\"üìâ Loss Function: CrossEntropyLoss\")\n","print(f\"   ‚Ä¢ Combines LogSoftmax + NLLLoss\")\n","print(f\"   ‚Ä¢ Suitable for multi-class classification\")\n","print(f\"   ‚Ä¢ Expects raw logits (not probabilities)\")\n","\n","# Optimizer\n","optimizer = optim.Adam(\n","    model.parameters(),\n","    lr=CONFIG['learning_rate']\n",")\n","\n","print(f\"\\n‚öôÔ∏è Optimizer: Adam\")\n","print(f\"   ‚Ä¢ Learning rate: {CONFIG['learning_rate']}\")\n","print(f\"   ‚Ä¢ Adaptive learning rates per parameter\")\n","print(f\"   ‚Ä¢ Momentum and adaptive estimates\")\n","\n","print(f\"\\n‚úÖ Training components ready!\")\n","\n","print(\"\\nüîß DEFINING TRAINING HELPER FUNCTIONS\")\n","print(\"=\"*60)\n","\n","def save_checkpoint(model, optimizer, epoch, batch_idx, loss, accuracy, filepath):\n","    \"\"\"\n","    Save model checkpoint to disk\n","\n","    Args:\n","        model: The neural network model\n","        optimizer: The optimizer\n","        epoch: Current epoch number\n","        batch_idx: Current batch index\n","        loss: Current loss value\n","        accuracy: Current accuracy\n","        filepath: Where to save the checkpoint\n","    \"\"\"\n","    checkpoint = {\n","        'epoch': epoch,\n","        'batch_idx': batch_idx,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'loss': loss,\n","        'accuracy': accuracy,\n","    }\n","    torch.save(checkpoint, filepath)\n","    print(f\"   üíæ Checkpoint saved: {os.path.basename(filepath)}\")\n","\n","\n","def load_checkpoint(model, optimizer, filepath):\n","    \"\"\"\n","    Load model checkpoint from disk\n","\n","    Args:\n","        model: The neural network model\n","        optimizer: The optimizer\n","        filepath: Path to checkpoint file\n","\n","    Returns:\n","        epoch, batch_idx: Resume training from these values\n","    \"\"\"\n","    checkpoint = torch.load(filepath)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    epoch = checkpoint['epoch']\n","    batch_idx = checkpoint['batch_idx']\n","    loss = checkpoint['loss']\n","    accuracy = checkpoint['accuracy']\n","\n","    print(f\"‚úÖ Checkpoint loaded: {os.path.basename(filepath)}\")\n","    print(f\"   Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss:.4f}, Acc: {accuracy:.2f}%\")\n","\n","    return epoch, batch_idx\n","\n","\n","def train_one_epoch(model, train_loader, criterion, optimizer, device, epoch,\n","                   checkpoint_interval, save_dir):\n","    \"\"\"\n","    Train model for one epoch with checkpointing\n","\n","    Args:\n","        model: Neural network\n","        train_loader: DataLoader for training data\n","        criterion: Loss function\n","        optimizer: Optimizer\n","        device: GPU/CPU device\n","        epoch: Current epoch number\n","        checkpoint_interval: Save checkpoint every N samples\n","        save_dir: Directory to save checkpoints\n","\n","    Returns:\n","        avg_loss, avg_accuracy: Average metrics for the epoch\n","    \"\"\"\n","    model.train()  # Set model to training mode\n","\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","    samples_processed = 0\n","\n","    # Progress bar for batches\n","    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n","\n","    for batch_idx, (images, labels) in enumerate(pbar):\n","        # Move data to device\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # Zero gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass\n","        loss.backward()\n","\n","        # Update weights\n","        optimizer.step()\n","\n","        # Calculate accuracy\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","        # Update running loss\n","        running_loss += loss.item()\n","        samples_processed += images.size(0)\n","\n","        # Update progress bar\n","        current_accuracy = 100 * correct / total\n","        pbar.set_postfix({\n","            'loss': f'{loss.item():.4f}',\n","            'acc': f'{current_accuracy:.2f}%'\n","        })\n","\n","        # Save checkpoint every N samples\n","        if (samples_processed % checkpoint_interval) < images.size(0):\n","            avg_loss = running_loss / (batch_idx + 1)\n","            checkpoint_path = os.path.join(\n","                save_dir,\n","                f'checkpoint_epoch{epoch+1}_batch{batch_idx+1}.pt'\n","            )\n","            save_checkpoint(\n","                model, optimizer, epoch, batch_idx,\n","                avg_loss, current_accuracy, checkpoint_path\n","            )\n","\n","    # Calculate epoch averages\n","    avg_loss = running_loss / len(train_loader)\n","    avg_accuracy = 100 * correct / total\n","\n","    return avg_loss, avg_accuracy\n","\n","print(\"‚úÖ Helper functions defined:\")\n","print(\"   ‚Ä¢ save_checkpoint() - Save model state\")\n","print(\"   ‚Ä¢ load_checkpoint() - Load model state\")\n","print(\"   ‚Ä¢ train_one_epoch() - Train for one epoch with checkpoints\")\n","\n","\n","# Training history\n","history = {\n","    'train_loss': [],\n","    'train_accuracy': []\n","}\n","\n","# Calculate total training info\n","total_batches = len(train_loader)\n","total_samples = len(train_loader.dataset)\n","batches_per_checkpoint = CONFIG['checkpoint_interval'] // CONFIG['batch_size']\n","\n","print(f\"\\nüìä Training Configuration:\")\n","print(f\"   Total epochs: {CONFIG['num_epochs']}\")\n","print(f\"   Batches per epoch: {total_batches:,}\")\n","print(f\"   Samples per epoch: {total_samples:,}\")\n","print(f\"   Checkpoint every {CONFIG['checkpoint_interval']:,} samples (~{batches_per_checkpoint} batches)\")\n","print(f\"\\n‚è±Ô∏è Estimated time per epoch: ~10-15 minutes (with GPU)\")\n","print(f\"‚è±Ô∏è Total estimated time: ~{CONFIG['num_epochs'] * 12} minutes\")\n","\n","print(f\"\\n{'='*60}\")\n","print(\"üéØ TRAINING STARTED\")\n","print(f\"{'='*60}\\n\")\n","\n","# Training loop\n","start_time = time.time()\n","\n","for epoch in range(CONFIG['num_epochs']):\n","    print(f\"\\nüìÖ Epoch {epoch + 1}/{CONFIG['num_epochs']}\")\n","    print(\"-\" * 60)\n","\n","    # Train for one epoch\n","    train_loss, train_acc = train_one_epoch(\n","        model=model,\n","        train_loader=train_loader,\n","        criterion=criterion,\n","        optimizer=optimizer,\n","        device=device,\n","        epoch=epoch,\n","        checkpoint_interval=CONFIG['checkpoint_interval'],\n","        save_dir=CONFIG['save_dir']\n","    )\n","\n","    # Store metrics\n","    history['train_loss'].append(train_loss)\n","    history['train_accuracy'].append(train_acc)\n","\n","    # Print epoch summary\n","    print(f\"\\nüìä Epoch {epoch + 1} Summary:\")\n","    print(f\"   Average Loss: {train_loss:.4f}\")\n","    print(f\"   Average Accuracy: {train_acc:.2f}%\")\n","\n","    # Save epoch checkpoint\n","    epoch_checkpoint_path = os.path.join(\n","        CONFIG['save_dir'],\n","        f'model_epoch{epoch+1}.pt'\n","    )\n","    save_checkpoint(\n","        model, optimizer, epoch, len(train_loader)-1,\n","        train_loss, train_acc, epoch_checkpoint_path\n","    )\n","\n","    print(f\"   üíæ Epoch checkpoint saved\")\n","\n","# Training complete\n","total_time = time.time() - start_time\n","print(f\"\\n{'='*60}\")\n","print(\"üéâ TRAINING COMPLETE!\")\n","print(f\"{'='*60}\")\n","print(f\"‚è±Ô∏è Total training time: {total_time/60:.2f} minutes\")\n","print(f\"üìä Final Training Accuracy: {history['train_accuracy'][-1]:.2f}%\")\n","print(f\"üìâ Final Training Loss: {history['train_loss'][-1]:.4f}\")\n","\n","fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n","\n","# Plot loss\n","axes[0].plot(range(1, CONFIG['num_epochs'] + 1), history['train_loss'],\n","             marker='o', linewidth=2, markersize=8, color='#e74c3c')\n","axes[0].set_xlabel('Epoch', fontsize=12)\n","axes[0].set_ylabel('Loss', fontsize=12)\n","axes[0].set_title('Training Loss Over Epochs', fontsize=14, fontweight='bold')\n","axes[0].grid(True, alpha=0.3)\n","axes[0].set_xticks(range(1, CONFIG['num_epochs'] + 1))\n","\n","# Plot accuracy\n","axes[1].plot(range(1, CONFIG['num_epochs'] + 1), history['train_accuracy'],\n","             marker='o', linewidth=2, markersize=8, color='#27ae60')\n","axes[1].set_xlabel('Epoch', fontsize=12)\n","axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n","axes[1].set_title('Training Accuracy Over Epochs', fontsize=14, fontweight='bold')\n","axes[1].grid(True, alpha=0.3)\n","axes[1].set_xticks(range(1, CONFIG['num_epochs'] + 1))\n","axes[1].set_ylim([0, 100])\n","\n","plt.tight_layout()\n","plt.show()\n","\n","print(\"‚úÖ Training curves displayed\")\n","\n","# Print improvement\n","initial_acc = history['train_accuracy'][0]\n","final_acc = history['train_accuracy'][-1]\n","improvement = final_acc - initial_acc\n","\n","print(f\"\\nüìä Training Progress:\")\n","print(f\"   Initial accuracy: {initial_acc:.2f}%\")\n","print(f\"   Final accuracy: {final_acc:.2f}%\")\n","print(f\"   Improvement: +{improvement:.2f}%\")\n","\n","# Save final model\n","final_model_path = os.path.join(CONFIG['save_dir'], 'final_model.pt')\n","\n","torch.save({\n","    'model_state_dict': model.state_dict(),\n","    'optimizer_state_dict': optimizer.state_dict(),\n","    'train_loss': history['train_loss'],\n","    'train_accuracy': history['train_accuracy'],\n","    'config': CONFIG,\n","    'num_epochs': CONFIG['num_epochs']\n","}, final_model_path)\n","\n","print(f\"‚úÖ Final model saved to:\")\n","print(f\"   {final_model_path}\")\n","\n","# List all saved checkpoints\n","print(f\"\\nüìÇ Saved checkpoints:\")\n","checkpoint_files = sorted([f for f in os.listdir(CONFIG['save_dir']) if f.endswith('.pt')])\n","for i, filename in enumerate(checkpoint_files, 1):\n","    filepath = os.path.join(CONFIG['save_dir'], filename)\n","    size_mb = os.path.getsize(filepath) / (1024**2)\n","    print(f\"   {i}. {filename} ({size_mb:.2f} MB)\")\n","\n","print(f\"\\n‚úÖ All checkpoints saved to Google Drive\")\n","print(f\"   These will persist even after session ends!\")\n","\n","# Load the final trained model\n","final_model_path = os.path.join(CONFIG['save_dir'], 'final_model.pt')\n","\n","if os.path.exists(final_model_path):\n","    checkpoint = torch.load(final_model_path)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    print(f\"‚úÖ Loaded final model from: {os.path.basename(final_model_path)}\")\n","\n","    # Display training history from checkpoint\n","    if 'train_accuracy' in checkpoint:\n","        print(f\"\\nüìä Training History:\")\n","        print(f\"   Final training accuracy: {checkpoint['train_accuracy'][-1]:.2f}%\")\n","        print(f\"   Final training loss: {checkpoint['train_loss'][-1]:.4f}\")\n","else:\n","    print(f\"‚ö†Ô∏è Final model not found, using current model state\")\n","\n","# Set model to evaluation mode\n","model.eval()\n","print(f\"\\n‚úÖ Model set to evaluation mode\")\n","print(f\"   (Dropout disabled, BatchNorm in eval mode)\")\n","\n","# Storage for predictions and labels\n","all_predictions = []\n","all_labels = []\n","all_probs = []\n","\n","print(f\"üìä Test set: {len(test_loader.dataset):,} samples\")\n","print(f\"   Processing {len(test_loader)} batches...\")\n","\n","# Disable gradient computation for evaluation\n","with torch.no_grad():\n","    for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n","        # Move to device\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(images)\n","\n","        # Get probabilities (apply softmax to logits)\n","        probs = F.softmax(outputs, dim=1)\n","\n","        # Get predicted class (0 or 1)\n","        _, predicted = torch.max(outputs, 1)\n","\n","        # Store results\n","        all_predictions.extend(predicted.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())\n","        all_probs.extend(probs.cpu().numpy())\n","\n","# Convert to numpy arrays\n","all_predictions = np.array(all_predictions)\n","all_labels = np.array(all_labels)\n","all_probs = np.array(all_probs)\n","\n","print(f\"\\n‚úÖ Evaluation complete!\")\n","print(f\"   Predictions collected: {len(all_predictions):,}\")\n","\n"]}]}